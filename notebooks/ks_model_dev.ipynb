{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "\n",
    "print(f'Numpy Version: {np.__version__}')\n",
    "print(f'Tensorflow Version: {tf.__version__}')\n",
    "print(f'Pandas Version: {pd.__version__}')\n",
    "print(f'sklearn Version: {sklearn.__version__}')\n",
    "print(f'seaborn Version: {sns.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Users/jasonrobinson/Downloads/Kickstarter_2018-05-16T03_20_20_822Z/Kickstarter038.csv')\n",
    "df2 = pd.read_csv('/Users/jasonrobinson/Downloads/Kickstarter_2019-05-14T03_20_08_560Z/Kickstarter013.csv')\n",
    "df = pd.concat([df1, df2], axis=1)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['state'] != 'canceled']\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing data leakage columns\n",
    "\n",
    "df = df[['category', 'main_category', 'currency', 'deadline', 'launched', 'country', 'state', 'goal']]\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting state into binary success and failure where success=1  and failure = 0 \n",
    "\n",
    "df = df.assign(outcome=(df['state'] == 'successful').astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['launched'] = pd.to_datetime(df['launched'])\n",
    "df['deadline'] = pd.to_datetime(df['deadline'])\n",
    "\n",
    "df = df.assign(hour_launched=df.launched.dt.hour,\n",
    "               day_launched=df.launched.dt.day,\n",
    "               month_launched=df.launched.dt.month,\n",
    "               year_launched=df.launched.dt.year)\n",
    "\n",
    "df = df.assign(day_deadline=df.launched.dt.day,\n",
    "               month_deadline=df.launched.dt.month,\n",
    "               year_deadline=df.launched.dt.year)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cat_features = ['category', 'currency', 'country', 'main_category']\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "encoded = df[cat_features].apply(encoder.fit_transform)\n",
    "encoded.head(10)\n",
    "\n",
    "df = df[['goal', 'hour_launched', 'day_launched', 'month_launched', 'year_launched','day_deadline', 'month_deadline', 'year_deadline', 'outcome']].join(encoded)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data Exploration\n",
    "\n",
    "    Descriptive statistics for key features\n",
    "    Visualizations for key features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model\n",
    "features = ['goal', 'hour_launched', 'day_launched', 'month_launched', 'year_launched','day_deadline', 'month_deadline', 'year_deadline', 'category', 'currency', 'country', 'main_category']\n",
    "target = 'outcome'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler \n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "X_numerical = X.drop(['main_category','country'], axis = 1)\n",
    "\n",
    "scaler.fit(X_numerical)\n",
    "\n",
    "scaled_X = scaler.transform(X_numerical)\n",
    "\n",
    "scaled_X = pd.DataFrame(scaled_X, columns = X_numerical.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(10, input_dim=10, activation='relu'),\n",
    "    Dense(1, activation='sigmoid'),    \n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(scaled_X, y,\n",
    "          epochs=10,\n",
    "          batch_size=32,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Model Approach #1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    Dense(64, input_dim=10, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid'),    \n",
    "])\n",
    "\n",
    "model2.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(scaled_X, y,\n",
    "          epochs=20,\n",
    "          batch_size=32,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Model Approach #2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introducing early stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "logdir = os.path.join(\"logs\", \"EarlyStopping-Loss\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "stop = EarlyStopping(monitor='val_accuracy', min_delta=0.005, patience=3)\n",
    "\n",
    "model3 = tf.keras.Sequential([\n",
    "    Dense(300, input_dim=10, activation='relu'),\n",
    "    Dense(150, activation='relu'),\n",
    "    Dense(75, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model3.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(scaled_X, y, epochs=99, \n",
    "          validation_split=0.2,\n",
    "          callbacks=[tensorboard_callback, stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Saving the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, '../models/model_name.joblib')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
